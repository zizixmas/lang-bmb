name: Benchmark Suite

on:
  # Run weekly on Sundays
  schedule:
    - cron: '0 0 * * 0'
  # Run on-demand
  workflow_dispatch:
    inputs:
      iterations:
        description: 'Number of benchmark iterations'
        required: false
        default: '5'
      category:
        description: 'Benchmark category (all, compute, contract, real_world, bootstrap)'
        required: false
        default: 'all'
  # Run on PRs that touch performance-critical files
  pull_request:
    paths:
      - 'bmb/src/codegen/**'
      - 'bmb/src/mir/**'
      - 'ecosystem/benchmark-bmb/**'

env:
  CARGO_TERM_COLOR: always

jobs:
  benchmark-native:
    name: Native Benchmark Suite (LLVM)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Setup Rust
        uses: dtolnay/rust-action@stable

      - name: Install LLVM 21
        run: |
          wget https://apt.llvm.org/llvm.sh
          chmod +x llvm.sh
          sudo ./llvm.sh 21
          echo "LLVM_SYS_210_PREFIX=/usr/lib/llvm-21" >> $GITHUB_ENV
          echo "/usr/lib/llvm-21/bin" >> $GITHUB_PATH

      - name: Verify LLVM installation
        run: |
          llvm-config --version
          clang --version

      - name: Cache cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            target/
          key: ${{ runner.os }}-cargo-llvm-${{ hashFiles('**/Cargo.lock') }}

      - name: Build BMB with LLVM
        run: cargo build --release --features llvm

      - name: Build BMB Runtime
        run: |
          cd bmb/runtime
          clang -c bmb_runtime.c -o bmb_runtime.o -O3
          ar rcs libbmb_runtime.a bmb_runtime.o
          echo "BMB_RUNTIME_PATH=$(pwd)/libbmb_runtime.a" >> $GITHUB_ENV

      - name: Build Benchmark Runner
        run: |
          cd ecosystem/benchmark-bmb/runner
          cargo build --release

      - name: Compile C Benchmarks
        run: |
          echo "=== Compiling C Benchmarks ==="
          for bench_dir in ecosystem/benchmark-bmb/benches/compute/*/c; do
            if [ -f "$bench_dir/main.c" ]; then
              name=$(basename $(dirname $bench_dir))
              echo "Compiling C: $name"
              gcc -O3 "$bench_dir/main.c" -o "$bench_dir/main" -lm 2>/dev/null || true
            fi
          done

      - name: Compile Rust Benchmarks
        run: |
          echo "=== Compiling Rust Benchmarks ==="
          for bench_dir in ecosystem/benchmark-bmb/benches/compute/*/rust; do
            if [ -f "$bench_dir/main.rs" ]; then
              name=$(basename $(dirname $bench_dir))
              echo "Compiling Rust: $name"
              rustc -O "$bench_dir/main.rs" -o "$bench_dir/main" 2>/dev/null || true
            fi
          done

      - name: Compile BMB Benchmarks (IR + clang -O3)
        run: |
          echo "=== Compiling BMB Benchmarks ==="
          for bench_dir in ecosystem/benchmark-bmb/benches/compute/*/bmb; do
            if [ -f "$bench_dir/main.bmb" ]; then
              name=$(basename $(dirname $bench_dir))
              echo "Compiling BMB: $name"

              # Generate LLVM IR
              ./target/release/bmb build "$bench_dir/main.bmb" --emit-ir -o "$bench_dir/main.ll" 2>/dev/null || continue

              # Compile with clang -O3
              clang -O3 "$bench_dir/main.ll" $BMB_RUNTIME_PATH -o "$bench_dir/main" -lm -no-pie 2>/dev/null || true
            fi
          done

      - name: Run Compute Benchmarks
        id: benchmark
        run: |
          echo "=== Running Compute Benchmarks ==="
          echo ""
          echo "| Benchmark | C (ms) | Rust (ms) | BMB (ms) | vs C | vs Rust | Gate |"
          echo "|-----------|--------|-----------|----------|------|---------|------|"

          GATE_PASSED=0
          GATE_TOTAL=0

          for bench_dir in ecosystem/benchmark-bmb/benches/compute/*/; do
            name=$(basename $bench_dir)
            c_bin="$bench_dir/c/main"
            rust_bin="$bench_dir/rust/main"
            bmb_bin="$bench_dir/bmb/main"

            c_time="-"
            rust_time="-"
            bmb_time="-"

            # Run C benchmark
            if [ -x "$c_bin" ]; then
              c_time=$(./target/release/bmb run -q "$c_bin" 2>/dev/null | grep -oP '\d+' || echo "-")
              if [ "$c_time" != "-" ]; then
                c_time_ms=$((c_time))
              fi
            fi

            # Run Rust benchmark
            if [ -x "$rust_bin" ]; then
              rust_start=$(date +%s%N)
              timeout 30s "$rust_bin" >/dev/null 2>&1 || true
              rust_end=$(date +%s%N)
              rust_time=$(( (rust_end - rust_start) / 1000000 ))
            fi

            # Run BMB benchmark
            if [ -x "$bmb_bin" ]; then
              bmb_start=$(date +%s%N)
              timeout 30s "$bmb_bin" >/dev/null 2>&1 || true
              bmb_end=$(date +%s%N)
              bmb_time=$(( (bmb_end - bmb_start) / 1000000 ))
            fi

            # Calculate ratios
            vs_c="-"
            vs_rust="-"
            gate="⏳"

            if [ "$c_time" != "-" ] && [ "$bmb_time" != "-" ] && [ "$c_time" -gt 0 ]; then
              ratio=$(echo "scale=2; $bmb_time / $c_time" | bc)
              vs_c="${ratio}x"

              GATE_TOTAL=$((GATE_TOTAL + 1))
              if (( $(echo "$ratio <= 1.10" | bc -l) )); then
                gate="✅"
                GATE_PASSED=$((GATE_PASSED + 1))
              else
                gate="❌"
              fi
            fi

            if [ "$rust_time" != "-" ] && [ "$bmb_time" != "-" ] && [ "$rust_time" -gt 0 ]; then
              ratio=$(echo "scale=2; $bmb_time / $rust_time" | bc)
              vs_rust="${ratio}x"
            fi

            echo "| $name | $c_time | $rust_time | $bmb_time | $vs_c | $vs_rust | $gate |"
          done

          echo ""
          echo "Gate #3.1 Status: $GATE_PASSED / $GATE_TOTAL benchmarks within 1.10x of C"

          if [ "$GATE_TOTAL" -gt 0 ] && [ "$GATE_PASSED" -eq "$GATE_TOTAL" ]; then
            echo "gate_status=PASSED" >> $GITHUB_OUTPUT
          else
            echo "gate_status=FAILED" >> $GITHUB_OUTPUT
          fi

      - name: Gate #3.1 Verification
        run: |
          if [ "${{ steps.benchmark.outputs.gate_status }}" != "PASSED" ]; then
            echo "::warning::Gate #3.1 not fully verified - some benchmarks may be missing or slow"
          else
            echo "::notice::Gate #3.1 PASSED - All compute benchmarks within 1.10x of C"
          fi

      - name: Save Benchmark Results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            ecosystem/benchmark-bmb/results/

  gate-summary:
    name: Gate Status Summary
    runs-on: ubuntu-latest
    needs: benchmark-native
    steps:
      - name: Summarize Gates
        run: |
          echo "# BMB Performance Gates Summary"
          echo ""
          echo "| Gate | Description | Target | Status |"
          echo "|------|-------------|--------|--------|"
          echo "| #3.1 | Compute benchmarks | ≤1.10x C | ${{ needs.benchmark-native.outputs.gate_status || '⏳' }} |"
          echo "| #3.2 | Benchmarks Game | ≤1.05x C | ⏳ |"
          echo "| #3.3 | Faster than C | 3+ benchmarks | ⏳ |"
          echo "| #4.1 | Self-compile | <60s | ✅ (0.56s) |"
